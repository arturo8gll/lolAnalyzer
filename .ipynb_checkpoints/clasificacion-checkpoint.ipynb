{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "import pygal\n",
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "base_html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "  <script type=\"text/javascript\" src=\"http://kozea.github.com/pygal.js/javascripts/svg.jquery.js\"></script>\n",
    "  <script type=\"text/javascript\" src=\"https://kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js\"\"></script>\n",
    "  </head>\n",
    "  <body>\n",
    "    <figure>\n",
    "      {rendered_chart}\n",
    "    </figure>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta seccion desarrolle un modulo de clasificacion para predecir si el usuario ganara o perdera su partida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./csv/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gameId\n",
      "platformId\n",
      "gameCreation\n",
      "gameDuration\n",
      "queueId\n",
      "mapId\n",
      "seasonId\n",
      "gameVersion\n",
      "gameMode\n",
      "gameType\n",
      "teamId\n",
      "win\n",
      "firstBlood\n",
      "firstTower\n",
      "firstInhibitor\n",
      "firstBaron\n",
      "firstDragon\n",
      "firstRiftHerald\n",
      "towerKills\n",
      "inhibitorKills\n",
      "baronKills\n",
      "dragonKills\n",
      "vilemawKills\n",
      "riftHeraldKills\n",
      "dominionVictoryScore\n",
      "participantId\n",
      "championId\n",
      "spell1Id\n",
      "spell2Id\n",
      "item0\n",
      "item1\n",
      "item2\n",
      "item3\n",
      "item4\n",
      "item5\n",
      "item6\n",
      "kills\n",
      "deaths\n",
      "assists\n",
      "largestKillingSpree\n",
      "largestMultiKill\n",
      "killingSprees\n",
      "longestTimeSpentLiving\n",
      "doubleKills\n",
      "tripleKills\n",
      "quadraKills\n",
      "pentaKills\n",
      "unrealKills\n",
      "totalDamageDealt\n",
      "magicDamageDealt\n",
      "physicalDamageDealt\n",
      "trueDamageDealt\n",
      "largestCriticalStrike\n",
      "totalDamageDealtToChampions\n",
      "magicDamageDealtToChampions\n",
      "physicalDamageDealtToChampions\n",
      "trueDamageDealtToChampions\n",
      "totalHeal\n",
      "totalUnitsHealed\n",
      "damageSelfMitigated\n",
      "damageDealtToObjectives\n",
      "damageDealtToTurrets\n",
      "visionScore\n",
      "timeCCingOthers\n",
      "totalDamageTaken\n",
      "magicalDamageTaken\n",
      "physicalDamageTaken\n",
      "trueDamageTaken\n",
      "goldEarned\n",
      "goldSpent\n",
      "turretKills\n",
      "totalMinionsKilled\n",
      "neutralMinionsKilled\n",
      "neutralMinionsKilledTeamJungle\n",
      "neutralMinionsKilledEnemyJungle\n",
      "totalTimeCrowdControlDealt\n",
      "champLevel\n",
      "visionWardsBoughtInGame\n",
      "sightWardsBoughtInGame\n",
      "wardsPlaced\n",
      "wardsKilled\n",
      "firstBloodKill\n",
      "firstBloodAssist\n",
      "firstTowerKill\n",
      "firstTowerAssist\n",
      "firstInhibitorKill\n",
      "firstInhibitorAssist\n",
      "combatPlayerScore\n",
      "objectivePlayerScore\n",
      "totalPlayerScore\n",
      "totalScoreRank\n",
      "playerScore0\n",
      "playerScore1\n",
      "playerScore2\n",
      "playerScore3\n",
      "playerScore4\n",
      "playerScore5\n",
      "playerScore6\n",
      "playerScore7\n",
      "playerScore8\n",
      "playerScore9\n",
      "perk0\n",
      "perk0Var1\n",
      "perk0Var2\n",
      "perk0Var3\n",
      "perk1\n",
      "perk1Var1\n",
      "perk1Var2\n",
      "perk1Var3\n",
      "perk2\n",
      "perk2Var1\n",
      "perk2Var2\n",
      "perk2Var3\n",
      "perk3\n",
      "perk3Var1\n",
      "perk3Var2\n",
      "perk3Var3\n",
      "perk4\n",
      "perk4Var1\n",
      "perk4Var2\n",
      "perk4Var3\n",
      "perk5\n",
      "perk5Var1\n",
      "perk5Var2\n",
      "perk5Var3\n",
      "perkPrimaryStyle\n",
      "perkSubStyle\n",
      "statPerk0\n",
      "statPerk1\n",
      "statPerk2\n",
      "creepsPerMinDeltas_10-20\n",
      "creepsPerMinDeltas_0-10\n",
      "xpPerMinDeltas_10-20\n",
      "xpPerMinDeltas_0-10\n",
      "goldPerMinDeltas_10-20\n",
      "goldPerMinDeltas_0-10\n",
      "csDiffPerMinDeltas_10-20\n",
      "csDiffPerMinDeltas_0-10\n",
      "xpDiffPerMinDeltas_10-20\n",
      "xpDiffPerMinDeltas_0-10\n",
      "damageTakenPerMinDeltas_10-20\n",
      "damageTakenPerMinDeltas_0-10\n",
      "damageTakenDiffPerMinDeltas_10-20\n",
      "damageTakenDiffPerMinDeltas_0-10\n",
      "lane\n",
      "role\n",
      "creepsPerMinDeltas_30-end\n",
      "creepsPerMinDeltas_20-30\n",
      "xpPerMinDeltas_30-end\n",
      "xpPerMinDeltas_20-30\n",
      "goldPerMinDeltas_30-end\n",
      "goldPerMinDeltas_20-30\n",
      "csDiffPerMinDeltas_30-end\n",
      "csDiffPerMinDeltas_20-30\n",
      "xpDiffPerMinDeltas_30-end\n",
      "xpDiffPerMinDeltas_20-30\n",
      "damageTakenPerMinDeltas_30-end\n",
      "damageTakenPerMinDeltas_20-30\n",
      "damageTakenDiffPerMinDeltas_30-end\n",
      "damageTakenDiffPerMinDeltas_20-30\n",
      "highestAchievedSeasonTier\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gameId 0\n",
      "platformId 0\n",
      "gameCreation 0\n",
      "gameDuration 0\n",
      "queueId 0\n",
      "mapId 0\n",
      "seasonId 0\n",
      "gameVersion 0\n",
      "gameMode 0\n",
      "gameType 0\n",
      "teamId 0\n",
      "win 0\n",
      "firstBlood 0\n",
      "firstTower 0\n",
      "firstInhibitor 0\n",
      "firstBaron 0\n",
      "firstDragon 0\n",
      "firstRiftHerald 0\n",
      "towerKills 0\n",
      "inhibitorKills 0\n",
      "baronKills 0\n",
      "dragonKills 0\n",
      "vilemawKills 0\n",
      "riftHeraldKills 0\n",
      "dominionVictoryScore 0\n",
      "participantId 0\n",
      "championId 0\n",
      "spell1Id 0\n",
      "spell2Id 0\n",
      "item0 0\n",
      "item1 0\n",
      "item2 0\n",
      "item3 0\n",
      "item4 0\n",
      "item5 0\n",
      "item6 0\n",
      "kills 0\n",
      "deaths 0\n",
      "assists 0\n",
      "largestKillingSpree 0\n",
      "largestMultiKill 0\n",
      "killingSprees 0\n",
      "longestTimeSpentLiving 0\n",
      "doubleKills 0\n",
      "tripleKills 0\n",
      "quadraKills 0\n",
      "pentaKills 0\n",
      "unrealKills 0\n",
      "totalDamageDealt 0\n",
      "magicDamageDealt 0\n",
      "physicalDamageDealt 0\n",
      "trueDamageDealt 0\n",
      "largestCriticalStrike 0\n",
      "totalDamageDealtToChampions 0\n",
      "magicDamageDealtToChampions 0\n",
      "physicalDamageDealtToChampions 0\n",
      "trueDamageDealtToChampions 0\n",
      "totalHeal 0\n",
      "totalUnitsHealed 0\n",
      "damageSelfMitigated 0\n",
      "damageDealtToObjectives 0\n",
      "damageDealtToTurrets 0\n",
      "visionScore 0\n",
      "timeCCingOthers 0\n",
      "totalDamageTaken 0\n",
      "magicalDamageTaken 0\n",
      "physicalDamageTaken 0\n",
      "trueDamageTaken 0\n",
      "goldEarned 0\n",
      "goldSpent 0\n",
      "turretKills 0\n",
      "totalMinionsKilled 0\n",
      "neutralMinionsKilled 0\n",
      "neutralMinionsKilledTeamJungle 0\n",
      "neutralMinionsKilledEnemyJungle 0\n",
      "totalTimeCrowdControlDealt 0\n",
      "champLevel 0\n",
      "visionWardsBoughtInGame 0\n",
      "sightWardsBoughtInGame 0\n",
      "wardsPlaced 0\n",
      "wardsKilled 0\n",
      "firstBloodKill 3\n",
      "firstBloodAssist 3\n",
      "firstTowerKill 20\n",
      "firstTowerAssist 20\n",
      "firstInhibitorKill 70\n",
      "firstInhibitorAssist 70\n",
      "combatPlayerScore 0\n",
      "objectivePlayerScore 0\n",
      "totalPlayerScore 0\n",
      "totalScoreRank 0\n",
      "playerScore0 0\n",
      "playerScore1 0\n",
      "playerScore2 0\n",
      "playerScore3 0\n",
      "playerScore4 0\n",
      "playerScore5 0\n",
      "playerScore6 0\n",
      "playerScore7 0\n",
      "playerScore8 0\n",
      "playerScore9 0\n",
      "perk0 2\n",
      "perk0Var1 2\n",
      "perk0Var2 2\n",
      "perk0Var3 2\n",
      "perk1 2\n",
      "perk1Var1 2\n",
      "perk1Var2 2\n",
      "perk1Var3 2\n",
      "perk2 2\n",
      "perk2Var1 2\n",
      "perk2Var2 2\n",
      "perk2Var3 2\n",
      "perk3 2\n",
      "perk3Var1 2\n",
      "perk3Var2 2\n",
      "perk3Var3 2\n",
      "perk4 2\n",
      "perk4Var1 2\n",
      "perk4Var2 2\n",
      "perk4Var3 2\n",
      "perk5 2\n",
      "perk5Var1 2\n",
      "perk5Var2 2\n",
      "perk5Var3 2\n",
      "perkPrimaryStyle 2\n",
      "perkSubStyle 2\n",
      "statPerk0 344\n",
      "statPerk1 344\n",
      "statPerk2 344\n",
      "creepsPerMinDeltas_10-20 79\n",
      "creepsPerMinDeltas_0-10 21\n",
      "xpPerMinDeltas_10-20 79\n",
      "xpPerMinDeltas_0-10 21\n",
      "goldPerMinDeltas_10-20 79\n",
      "goldPerMinDeltas_0-10 21\n",
      "csDiffPerMinDeltas_10-20 177\n",
      "csDiffPerMinDeltas_0-10 120\n",
      "xpDiffPerMinDeltas_10-20 177\n",
      "xpDiffPerMinDeltas_0-10 120\n",
      "damageTakenPerMinDeltas_10-20 79\n",
      "damageTakenPerMinDeltas_0-10 21\n",
      "damageTakenDiffPerMinDeltas_10-20 177\n",
      "damageTakenDiffPerMinDeltas_0-10 120\n",
      "lane 0\n",
      "role 0\n",
      "creepsPerMinDeltas_30-end 502\n",
      "creepsPerMinDeltas_20-30 363\n",
      "xpPerMinDeltas_30-end 502\n",
      "xpPerMinDeltas_20-30 363\n",
      "goldPerMinDeltas_30-end 502\n",
      "goldPerMinDeltas_20-30 363\n",
      "csDiffPerMinDeltas_30-end 515\n",
      "csDiffPerMinDeltas_20-30 402\n",
      "xpDiffPerMinDeltas_30-end 515\n",
      "xpDiffPerMinDeltas_20-30 402\n",
      "damageTakenPerMinDeltas_30-end 502\n",
      "damageTakenPerMinDeltas_20-30 363\n",
      "damageTakenDiffPerMinDeltas_30-end 515\n",
      "damageTakenDiffPerMinDeltas_20-30 402\n",
      "highestAchievedSeasonTier 28\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(df.isna().sum().index, df.isna().sum()):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt=\"win\"\n",
    "ls_pred=[\"kills\",\"deaths\",\"assists\",\"turretKills\",\"totalDamageDealt\",\n",
    "\"magicDamageDealt\",\n",
    "\"physicalDamageDealt\",\n",
    "\"trueDamageDealt\",\n",
    "\"wardsPlaced\",\n",
    "\"wardsKilled\",\n",
    "\"totalDamageTaken\",\n",
    "\"magicalDamageTaken\",\n",
    "\"physicalDamageTaken\",\n",
    "\"trueDamageTaken\",\n",
    "\"totalDamageDealt\",\n",
    "\"magicDamageDealt\",\n",
    "\"physicalDamageDealt\",\n",
    "\"trueDamageDealt\",\n",
    "\"firstBlood\",\n",
    "\"firstTower\",\n",
    "\"firstInhibitor\",\n",
    "\"firstBaron\",\n",
    "\"firstDragon\",\n",
    "\"firstRiftHerald\",\n",
    "\"towerKills\",\n",
    "\"inhibitorKills\",\n",
    "\"baronKills\",\n",
    "\"dragonKills\",\n",
    "\"riftHeraldKills\",\n",
    "\"gameDuration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "escalar=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[ls_pred], df[tgt], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=escalar.fit_transform(X_train)\n",
    "X_test=escalar.transform(X_test)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_grid = {\n",
    "    'penalty':['l1','l2','elasticnet','none'],\n",
    "    'dual':[True,False],\n",
    "    'class_weight':['balanced','None'],\n",
    "    'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'tol':[.0001,.0002,.0003,.0004,.0005],\n",
    "    'multi_class':['ovr', 'multinomial', 'auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8660049627791563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arturo/virtualenv/ml/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "regLog=LogisticRegression()\n",
    "clf = GridSearchCV(regLog, reg_grid, cv=4, error_score=-1000, n_jobs=-1, scoring=\"accuracy\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best score: \" + str(clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='None', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='ovr', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "regLog=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arturo/virtualenv/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regLog.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regLog.predict(X_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kills', 0.8593373281613672),\n",
       " ('deaths', -1.46451913628026),\n",
       " ('assists', 1.5542760374750484),\n",
       " ('turretKills', 0.5540799579859407),\n",
       " ('totalDamageDealt', 0.014571877827540703),\n",
       " ('magicDamageDealt', -0.0857283784163155),\n",
       " ('physicalDamageDealt', 0.053318043042450955),\n",
       " ('trueDamageDealt', 0.06051796650294791),\n",
       " ('wardsPlaced', -0.22816143334712682),\n",
       " ('wardsKilled', -0.22554956596432837),\n",
       " ('totalDamageTaken', -0.10675171271269127),\n",
       " ('magicalDamageTaken', -0.0002738759395426746),\n",
       " ('physicalDamageTaken', -0.00020634048817493988),\n",
       " ('trueDamageTaken', -0.5818328248418969),\n",
       " ('totalDamageDealt', 0.014571877827540703),\n",
       " ('magicDamageDealt', -0.0857283784163155),\n",
       " ('physicalDamageDealt', 0.05331804304245099),\n",
       " ('trueDamageDealt', 0.060517966502947926),\n",
       " ('firstBlood', -0.11858641265084706),\n",
       " ('firstTower', 0.2121378712602401),\n",
       " ('firstInhibitor', 0.29055253106251344),\n",
       " ('firstBaron', -0.3812729103314979),\n",
       " ('firstDragon', -0.21926106651214997),\n",
       " ('firstRiftHerald', 0.0626929626109602),\n",
       " ('towerKills', 1.3871612698488267),\n",
       " ('inhibitorKills', 0.6880594607066706),\n",
       " ('baronKills', 0.1507131028981022),\n",
       " ('dragonKills', 0.716640131134978),\n",
       " ('riftHeraldKills', 0.0626929626109602),\n",
       " ('gameDuration', -0.8688884446551495)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x, y) for x, y in zip(ls_pred, regLog.coef_[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arturo/virtualenv/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/arturo/virtualenv/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/arturo/virtualenv/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.87407407, 0.85185185, 0.87218045])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(regLog, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arturo/virtualenv/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/arturo/virtualenv/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/arturo/virtualenv/ml/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = cross_val_predict(regLog, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[131,  27],\n",
       "       [ 27, 218]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.889795918367347"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train, y_train_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.889795918367347"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.889795918367347"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " f1_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(regLog, \"./logistic.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_pickle(\"./logistic.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     113\n",
       "False     86\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(test.predict(X_test)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     107\n",
       "False     92\n",
       "Name: win, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True, False, False,  True, False,  True,\n",
       "       False,  True,  True, False,  True, False, False, False,  True,\n",
       "       False,  True,  True, False,  True,  True, False, False, False,\n",
       "       False,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        True, False, False,  True,  True, False, False,  True,  True,\n",
       "       False,  True, False,  True,  True, False,  True,  True, False,\n",
       "        True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "       False, False,  True,  True,  True,  True, False,  True,  True,\n",
       "        True, False,  True, False,  True, False, False,  True, False,\n",
       "        True,  True, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False,  True, False,  True, False,  True,\n",
       "        True,  True, False,  True,  True,  True, False, False, False,\n",
       "       False,  True,  True, False,  True,  True, False,  True,  True,\n",
       "        True, False, False,  True,  True, False,  True,  True,  True,\n",
       "       False, False, False,  True,  True,  True, False,  True,  True,\n",
       "       False,  True, False,  True, False,  True, False,  True, False,\n",
       "       False,  True, False, False,  True, False,  True,  True, False,\n",
       "        True,  True, False,  True, False, False,  True,  True,  True,\n",
       "        True, False, False, False, False,  True,  True, False,  True,\n",
       "        True,  True, False,  True,  True, False,  True,  True,  True,\n",
       "       False, False, False,  True,  True,  True, False,  True, False,\n",
       "        True,  True, False, False,  True, False, False, False,  True,\n",
       "       False])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
